{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFlorida International Univeristy - Data Science MS\\nCAP 5640 - NLP - Spring 2019\\nAndrea Garcia and Constanza Schubert\\n\\nJSON files to Python Dataframe\\n'"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Florida International Univeristy - Data Science MS\n",
    "CAP 5640 - NLP - Spring 2019\n",
    "Andrea Garcia and Constanza Schubert\n",
    "\n",
    "JSON files to Python Dataframe\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: READ FILE AND DELETE BLANK LINES\n",
    "\n",
    "def deleteblanks(filetoedit, newfilename):\n",
    "    #Accepts two .json files as input, original file name (needs cleaning) and new file name (function will create new  .json clean file under this name) \n",
    "    newfile = open(newfilename, 'w')\n",
    "    with open(filetoedit, 'r') as f:\n",
    "        print (\"\".join(fileline for fileline in f if not fileline.isspace()), file=newfile)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: CREATE NESTED DICTIONARY\n",
    "\n",
    "def createdict(filename):\n",
    "    #Accepts a .json file as input and converts data into a nested dictionary. File must not contain any empty lines before, throughout or after main body.\n",
    "    with open(filename, \"r\") as jsondata:\n",
    "        tweetlines = []\n",
    "        for tline in jsondata:\n",
    "            tweetlines.append(tline)\n",
    "\n",
    "    tweetdict = {}\n",
    "    i = 0\n",
    "    while i < len(tweetlines):\n",
    "        tweetdict[i + 1] = json.loads(tweetlines[i])\n",
    "        i += 1\n",
    "    return tweetdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix function to expand out user, extended_tweet, retweet_status, and quoted status columns\n",
    "#for user I need user_id and for extended_tweet I need full_text\n",
    "#for retweets: retweet_status -> full_text\n",
    "\n",
    "# STEP 5: CREATE DATAFRAME FROM DICTIONARY\n",
    "\n",
    "def createdtframe(tweetdict):\n",
    "    #Accepts python dictionary as input and converts to dataframe using keys as columns and values as rows\n",
    "    #Columns comprised of only top level keys\n",
    "    df = pd.DataFrame.from_dict(tweetdict, orient='index')\n",
    "    df = df.join(pd.DataFrame(df['extended_tweet'].to_dict()).T,rsuffix='_extended')\n",
    "    df = df.join(pd.DataFrame(df['retweeted_status'].to_dict()).T,rsuffix='_retweeted')\n",
    "    #df = df.join(pd.DataFrame(df['quoted_status'].to_dict()).T,rsuffix='_quoted')\n",
    "    #Get full_text of retweet\n",
    "    df = df.join(pd.DataFrame(df['extended_tweet_retweeted'].to_dict()).T[['full_text']],rsuffix='_retweeted')\n",
    "    keep_columns= ['created_at',\n",
    "                    'id_str',\n",
    "                    'text',\n",
    "                    'full_text',\n",
    "                    'id_str_retweeted',\n",
    "                    'text_retweeted',\n",
    "                  'full_text_retweeted']\n",
    "\n",
    "    df = df[keep_columns]\n",
    "    \n",
    "    #For retweets, replace text value with text_retweeted, getting rid of the RT before the text\n",
    "    #Also applies for retweets\n",
    "    df['text']=np.where(df['id_str_retweeted'].isnull(),df['text'],df['text_retweeted'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process Apple and Samsung JSON files using helper functions\n",
    "apple_dict = createdict('.\\Data\\clean_apple.json')\n",
    "samsung_dict = createdict('.\\Data\\clean_samsung.json')\n",
    "apple_df=createdtframe(apple_dict)\n",
    "samsung_df=createdtframe(samsung_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>full_text</th>\n",
       "      <th>id_str_retweeted</th>\n",
       "      <th>text_retweeted</th>\n",
       "      <th>full_text_retweeted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun Jan 27 19:24:51 +0000 2019</td>\n",
       "      <td>1089605170252705799</td>\n",
       "      <td>Ok guys its time for Dimonds available now in ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1088416710225526789</td>\n",
       "      <td>Ok guys its time for Dimonds available now in ...</td>\n",
       "      <td>Ok guys its time for Dimonds available now in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sun Jan 27 19:24:58 +0000 2019</td>\n",
       "      <td>1089605199587618817</td>\n",
       "      <td>It makes me chuckle when articles claim that t...</td>\n",
       "      <td>It makes me chuckle when articles claim that t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sun Jan 27 19:25:01 +0000 2019</td>\n",
       "      <td>1089605211864399874</td>\n",
       "      <td>This was pretty cool! Thank you @apple for hav...</td>\n",
       "      <td>This was pretty cool! Thank you @apple for hav...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun Jan 27 19:25:06 +0000 2019</td>\n",
       "      <td>1089605236812103680</td>\n",
       "      <td>@BulletinAtomic @POTUS @DAVOS @WEF @ENERGY @YE...</td>\n",
       "      <td>@BulletinAtomic @POTUS @DAVOS @WEF @ENERGY @YE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sun Jan 27 19:25:26 +0000 2019</td>\n",
       "      <td>1089605318366191616</td>\n",
       "      <td>I’m pretty sure I just discovered that @Family...</td>\n",
       "      <td>I’m pretty sure I just discovered that @Family...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at               id_str  \\\n",
       "1  Sun Jan 27 19:24:51 +0000 2019  1089605170252705799   \n",
       "2  Sun Jan 27 19:24:58 +0000 2019  1089605199587618817   \n",
       "3  Sun Jan 27 19:25:01 +0000 2019  1089605211864399874   \n",
       "4  Sun Jan 27 19:25:06 +0000 2019  1089605236812103680   \n",
       "5  Sun Jan 27 19:25:26 +0000 2019  1089605318366191616   \n",
       "\n",
       "                                                text  \\\n",
       "1  Ok guys its time for Dimonds available now in ...   \n",
       "2  It makes me chuckle when articles claim that t...   \n",
       "3  This was pretty cool! Thank you @apple for hav...   \n",
       "4  @BulletinAtomic @POTUS @DAVOS @WEF @ENERGY @YE...   \n",
       "5  I’m pretty sure I just discovered that @Family...   \n",
       "\n",
       "                                           full_text     id_str_retweeted  \\\n",
       "1                                                NaN  1088416710225526789   \n",
       "2  It makes me chuckle when articles claim that t...                  NaN   \n",
       "3  This was pretty cool! Thank you @apple for hav...                  NaN   \n",
       "4  @BulletinAtomic @POTUS @DAVOS @WEF @ENERGY @YE...                  NaN   \n",
       "5  I’m pretty sure I just discovered that @Family...                  NaN   \n",
       "\n",
       "                                      text_retweeted  \\\n",
       "1  Ok guys its time for Dimonds available now in ...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "5                                                NaN   \n",
       "\n",
       "                                 full_text_retweeted  \n",
       "1  Ok guys its time for Dimonds available now in ...  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5                                                NaN  "
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retweets\n",
    "# Retweets should be discarded only if original tweet is in corpus.\n",
    "\n",
    "#Search for retweet as original tweet in corpus\n",
    "def filter_retweets(df):\n",
    "    original_tweet=list(df[df['id_str_retweeted'].notnull()]['id_str_retweeted'])\n",
    "    #if original tweet is in corpus, discard retweet by id_str_retweeted\n",
    "    retweets_discard = list(df[df['id_str'].isin(original_tweet)]['id_str'])\n",
    "    df = df[~df['id_str_retweeted'].isin(retweets_discard)]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to check whether a record is an extended tweeet and if so, replace extended tweet on text field\n",
    "\n",
    "def extract_extended_tweet(df):\n",
    "    df['text']=np.where(df['full_text'].isnull(),df['text'],df['full_text'])\n",
    "    #for retweets\n",
    "    df['text']=np.where(df['full_text_retweeted'].isnull(),df['text'],df['full_text_retweeted'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text preprocessing functions\n",
    "\n",
    "def upper_repl(match):\n",
    "    return  match.group(1).capitalize()\n",
    "\n",
    "def clean_html(text):\n",
    "    soup = BeautifulSoup(text, 'html5lib')    \n",
    "    souped = soup.get_text()\n",
    "    return souped\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    #Utility function to clean the text in a tweet by removing links, twitter handles, and special characters using regex\n",
    "    #keeps basic punctuation because you need it for dependency parsing\n",
    "    #currently keeps hashtags separated by a space. should be separate hashtags like sentences?\n",
    "    #re.sub(\"(@[A-Za-z0-9_]+)|([^0-9A-Za-z\\.,:;!?'$# \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet)\n",
    "    t0=re.sub(\"([^0-9A-Za-z\\.,:;!?'$@# \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet)\n",
    "    #return list of hashtag terms for reference\n",
    "    t_handles=re.compile(r\"@[A-Za-z0-9_]+\").findall(tweet)\n",
    "    \n",
    "    #remove hashtag symbol from twitter handles and capitalize terms\n",
    "    return t_handles, re.sub('@([A-Za-z0-9_]+)',upper_repl,t0)\n",
    "\n",
    "#Emoticon handling\n",
    "def remove_emojis(tweet):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    return emoji_pattern.sub(r'',tweet)\n",
    "\n",
    "#need function to remove extra whitespace: all tabs, newlines, and other whitespace-like characters\n",
    "def remove_whitespace(tweet):\n",
    "    return re.sub('\\s+',' ',tweet).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This was pretty cool! Thank you @apple for having me. And thank you to everyone who came !! Had so much fun, super cool chatting about production and songwriting too! '"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t=\"This was pretty cool! Thank you @apple for having me. And thank you to everyone who came !! Had so much fun, super cool chatting about production and songwriting too! \"\n",
    "# re.findall(r'@([A-Za-z0-9_]+)',t)\n",
    "# # def upper_repl(match):\n",
    "# #     return  match.group(1).capitalize()\n",
    "# re.sub('@([A-Za-z0-9_]+)',upper_repl,t)\n",
    "\n",
    "# re.sub(\"([^0-9A-Za-z\\.,:;!?'@$# \\t])|(\\w+:\\/\\/\\S+)\", \" \", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtag_list(tweet):\n",
    "    #return list of hashtag terms for reference\n",
    "    splithash=re.compile(r\"#(\\w+)\")\n",
    "    return splithash.findall(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_hashtags(tweet):\n",
    "    #Step 1: return text with hashtags separated by semicolons\n",
    "    p1=r'#(\\w+)'\n",
    "    t=re.sub(p1,r'\\1;',tweet)\n",
    "    #Step 2: split up hashtags consisting of multiple capitalized words into separate words\n",
    "    t1=' '.join(re.findall(r'[A-Z]?[^A-Z\\s]+|[A-Z]+', t))\n",
    "    #t1=re.sub( r\"([A-Z])\", r\" \\1\", t)\n",
    "    #remove whitespace\n",
    "    t1=remove_whitespace(t1)\n",
    "    return t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "\n",
    "def tokenize(df):\n",
    "    df['tokenized_tweets'] = df.apply(lambda row: word_tokenize(row['sentences']), axis=1)\n",
    "    #lowercase\n",
    "    df['tokenized_tweets'] = df['tokenized_tweets'].apply(lambda x: [item.lower() for item in x])\n",
    "    return df\n",
    "\n",
    "#Removal of stop words\n",
    "def remove_stopwords(df):\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    df['tweet_no_stop']=df['tokenized_tweets'].apply(lambda x: [item for item in x if item not in stops])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply text preprocessing functions\n",
    "\n",
    "def preprocess_text(df):\n",
    "    #In this particular order\n",
    "    df=filter_retweets(df)\n",
    "    df=extract_extended_tweet(df)\n",
    "    df['text']=df['text'].apply(remove_emojis)\n",
    "    df['text'] = df['text'].apply(clean_html)\n",
    "    df['Twitter handles'],df['text'] = zip(*df['text'].apply(clean_tweet))\n",
    "    df['Hashtags'] = df['text'].apply(hashtag_list)\n",
    "    df['text']=df['text'].apply(handle_hashtags)\n",
    "    df['text']=df['text'].apply(remove_whitespace)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cschu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\cschu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\cschu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\Users\\cschu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\cschu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\cschu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\cschu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\cschu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "#Processed tweets are in df['text'] column\n",
    "apple_clean=preprocess_text(apple_df)\n",
    "samsung_clean=preprocess_text(samsung_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>full_text</th>\n",
       "      <th>id_str_retweeted</th>\n",
       "      <th>text_retweeted</th>\n",
       "      <th>full_text_retweeted</th>\n",
       "      <th>Twitter handles</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun Jan 27 19:24:51 +0000 2019</td>\n",
       "      <td>1089605170252705799</td>\n",
       "      <td>Ok guys its time for Dimonds available now in ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1088416710225526789</td>\n",
       "      <td>Ok guys its time for Dimonds available now in ...</td>\n",
       "      <td>Ok guys its time for Dimonds available now in ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[cydia, theme, ios, jailbreak, anemone, iPhone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sun Jan 27 19:24:58 +0000 2019</td>\n",
       "      <td>1089605199587618817</td>\n",
       "      <td>It makes me chuckle when articles claim that t...</td>\n",
       "      <td>It makes me chuckle when articles claim that t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[@fitbit, @Apple]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sun Jan 27 19:25:01 +0000 2019</td>\n",
       "      <td>1089605211864399874</td>\n",
       "      <td>This was pretty cool! Thank you Apple for havi...</td>\n",
       "      <td>This was pretty cool! Thank you @apple for hav...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[@apple]</td>\n",
       "      <td>[todayatapple]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun Jan 27 19:25:06 +0000 2019</td>\n",
       "      <td>1089605236812103680</td>\n",
       "      <td>Bulletinatomic Potus Davos Wef Energy Yearsofl...</td>\n",
       "      <td>@BulletinAtomic @POTUS @DAVOS @WEF @ENERGY @YE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[@BulletinAtomic, @POTUS, @DAVOS, @WEF, @ENERG...</td>\n",
       "      <td>[HSS, LRAD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sun Jan 27 19:25:26 +0000 2019</td>\n",
       "      <td>1089605318366191616</td>\n",
       "      <td>I m pretty sure I just discovered that Familyg...</td>\n",
       "      <td>I’m pretty sure I just discovered that @Family...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[@FamilyGuyonFOX]</td>\n",
       "      <td>[FamilyGuy, Apple, ApplePencil]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at               id_str  \\\n",
       "1  Sun Jan 27 19:24:51 +0000 2019  1089605170252705799   \n",
       "2  Sun Jan 27 19:24:58 +0000 2019  1089605199587618817   \n",
       "3  Sun Jan 27 19:25:01 +0000 2019  1089605211864399874   \n",
       "4  Sun Jan 27 19:25:06 +0000 2019  1089605236812103680   \n",
       "5  Sun Jan 27 19:25:26 +0000 2019  1089605318366191616   \n",
       "\n",
       "                                                text  \\\n",
       "1  Ok guys its time for Dimonds available now in ...   \n",
       "2  It makes me chuckle when articles claim that t...   \n",
       "3  This was pretty cool! Thank you Apple for havi...   \n",
       "4  Bulletinatomic Potus Davos Wef Energy Yearsofl...   \n",
       "5  I m pretty sure I just discovered that Familyg...   \n",
       "\n",
       "                                           full_text     id_str_retweeted  \\\n",
       "1                                                NaN  1088416710225526789   \n",
       "2  It makes me chuckle when articles claim that t...                  NaN   \n",
       "3  This was pretty cool! Thank you @apple for hav...                  NaN   \n",
       "4  @BulletinAtomic @POTUS @DAVOS @WEF @ENERGY @YE...                  NaN   \n",
       "5  I’m pretty sure I just discovered that @Family...                  NaN   \n",
       "\n",
       "                                      text_retweeted  \\\n",
       "1  Ok guys its time for Dimonds available now in ...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "5                                                NaN   \n",
       "\n",
       "                                 full_text_retweeted  \\\n",
       "1  Ok guys its time for Dimonds available now in ...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "5                                                NaN   \n",
       "\n",
       "                                     Twitter handles  \\\n",
       "1                                                 []   \n",
       "2                                  [@fitbit, @Apple]   \n",
       "3                                           [@apple]   \n",
       "4  [@BulletinAtomic, @POTUS, @DAVOS, @WEF, @ENERG...   \n",
       "5                                  [@FamilyGuyonFOX]   \n",
       "\n",
       "                                            Hashtags  \n",
       "1  [cydia, theme, ios, jailbreak, anemone, iPhone...  \n",
       "2                                                 []  \n",
       "3                                     [todayatapple]  \n",
       "4                                        [HSS, LRAD]  \n",
       "5                    [FamilyGuy, Apple, ApplePencil]  "
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>full_text</th>\n",
       "      <th>id_str_retweeted</th>\n",
       "      <th>text_retweeted</th>\n",
       "      <th>full_text_retweeted</th>\n",
       "      <th>Twitter handles</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri Mar 01 03:01:41 +0000 2019</td>\n",
       "      <td>1101316548176695296</td>\n",
       "      <td>Whitestone Dome Glass for Samsung Galaxy S10 1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1101294096017022976</td>\n",
       "      <td>Whitestone Dome Glass for Samsung Galaxy S10/1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[@YouTube]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fri Mar 01 03:01:43 +0000 2019</td>\n",
       "      <td>1101316556993134593</td>\n",
       "      <td>Samsung Galaxy S10 Plus Durability Test New Fl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1101302978814738433</td>\n",
       "      <td>Samsung Galaxy S10 Plus Durability Test- New F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[@YouTube]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fri Mar 01 03:01:50 +0000 2019</td>\n",
       "      <td>1101316588353937408</td>\n",
       "      <td>Samsung Galaxy S10 DON ' T MESS IT UP Youtube</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1101261390847762432</td>\n",
       "      <td>Samsung Galaxy S10 - DON'T MESS IT UP https://...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[@YouTube]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fri Mar 01 03:01:51 +0000 2019</td>\n",
       "      <td>1101316589729841152</td>\n",
       "      <td>Just saw this on Amazon: Space Pop Sockets ......</td>\n",
       "      <td>Just saw this on Amazon: Space PopSockets ... ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[@amazon]</td>\n",
       "      <td>[iPhone, iPhoneXS, iPhone8, iPhone7Plus, iPhon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fri Mar 01 03:01:51 +0000 2019</td>\n",
       "      <td>1101316592040738816</td>\n",
       "      <td>Will the Galaxy S10 Fingerprint Scanner Work W...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1101233715114532864</td>\n",
       "      <td>Will the Galaxy S10+ Fingerprint Scanner Work ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[@YouTube]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at               id_str  \\\n",
       "1  Fri Mar 01 03:01:41 +0000 2019  1101316548176695296   \n",
       "2  Fri Mar 01 03:01:43 +0000 2019  1101316556993134593   \n",
       "3  Fri Mar 01 03:01:50 +0000 2019  1101316588353937408   \n",
       "4  Fri Mar 01 03:01:51 +0000 2019  1101316589729841152   \n",
       "5  Fri Mar 01 03:01:51 +0000 2019  1101316592040738816   \n",
       "\n",
       "                                                text  \\\n",
       "1  Whitestone Dome Glass for Samsung Galaxy S10 1...   \n",
       "2  Samsung Galaxy S10 Plus Durability Test New Fl...   \n",
       "3      Samsung Galaxy S10 DON ' T MESS IT UP Youtube   \n",
       "4  Just saw this on Amazon: Space Pop Sockets ......   \n",
       "5  Will the Galaxy S10 Fingerprint Scanner Work W...   \n",
       "\n",
       "                                           full_text     id_str_retweeted  \\\n",
       "1                                                NaN  1101294096017022976   \n",
       "2                                                NaN  1101302978814738433   \n",
       "3                                                NaN  1101261390847762432   \n",
       "4  Just saw this on Amazon: Space PopSockets ... ...                  NaN   \n",
       "5                                                NaN  1101233715114532864   \n",
       "\n",
       "                                      text_retweeted full_text_retweeted  \\\n",
       "1  Whitestone Dome Glass for Samsung Galaxy S10/1...                 NaN   \n",
       "2  Samsung Galaxy S10 Plus Durability Test- New F...                 NaN   \n",
       "3  Samsung Galaxy S10 - DON'T MESS IT UP https://...                 NaN   \n",
       "4                                                NaN                 NaN   \n",
       "5  Will the Galaxy S10+ Fingerprint Scanner Work ...                 NaN   \n",
       "\n",
       "  Twitter handles                                           Hashtags  \n",
       "1      [@YouTube]                                                 []  \n",
       "2      [@YouTube]                                                 []  \n",
       "3      [@YouTube]                                                 []  \n",
       "4       [@amazon]  [iPhone, iPhoneXS, iPhone8, iPhone7Plus, iPhon...  \n",
       "5      [@YouTube]                                                 []  "
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samsung_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save as csv\n",
    "apple_clean.to_csv('.\\\\Data\\\\apple_processed.csv',index=False)\n",
    "samsung_clean.to_csv('.\\\\Data\\\\samsung_processed.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
